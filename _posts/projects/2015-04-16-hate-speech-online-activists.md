---
layout: project
title: Hate Speech and Online Activism
tags:
- Phillip R. Polefrone
category: public-discourse
type: semantic analysis
prompt: #GamerGate and movements like it have revitalized a longstanding debate on the limits of the "free-speech" argument when discussing hate speech. Combining theoretical, historical, and legal research with a quantitative semantic analysis of tweets using the #GamerGate hashtag will put recent events in context. It will also begin to answer the question: How does hate speech operate online? Where do tweets like those of #GamerGate fit in the current legal definitions of hate speech? And, crucially, how can an understanding of this evolving language be used to protect online activists?
snippet: 150
published: true
issue: 15
updates:

- date: 05/15
  type: grant
  text: "Project receives $5,000 from Columbia University's School of
International and Public Affairs (SIPA) and Carnegie to further research on
hate speech and the protection of online activists."

---

Since the beginning of #GamerGate in 2014, threats to online feminist activists
and their allies have been routine, as have bomb threats and public shaming on
Twitter and beyond. Legislators are scrambling to respond: in March 2015, to
take a recent example, Representative Katherine Clark called to strengthen the
parts of the Violence Against Women Act that protect victims of online stalking
and harassment. Measures such as these are obviously necessary, but several
fundamental questions remain unasked about the language under consideration:
How does online hate speech differ from previous forms of hate speech? Will the
legal structures that define threatening and criminally harassing language as
civil rights violations be able to keep up with the linguistic petri dish of
social media? How closely do these definitions describe the type of harassment
that is actually occurring, and are there any ways in which it is deficient? 

This project will attempt to answer these questions by analyzing the language
of a large corpus of tweets that use the #GamerGate hashtag. The vast majority
of the existing work on #GamerGate has been network analysis, and while such
work is unquestionably useful for any social media topic, its exclusion of
semantic content limits its applications. Most notably for my purposes, network
analysis does not allow us to ask whether and how these tweets operate as hate
speech.

To address this question will require several distinct modes of comparison. To
establish a reliable working definition of hate speech will require
close-reading of existing legislation and an historical overview of criminal
harassment in hate crime prosecution. When this foundation has been
established, corpus analysis of current and historical tweet content will be
able to begin. Finally, quantitative comparison of this corpus analysis with
recognized records of hate speech and criminal harassment will put these
utterances in a clear context. Simply put, the goal of the project will be to
provide quantitative support to existing scholarship on online hate crimes,
both to make it more useful to policy makers and to demonstrate the extent and
nature of an increasingly pernicious problem.

### Policy Application

This research could have a considerable impact on policy decisions because of
the amount of available data and the renewed focus on protecting online civil
liberties.The acts in question, by their nature, are easily traceable, and
samples from the past several years have been retained as datasets for prior
research. (New data can be easily gathered using Twitter's API.) The results of
this research can readily be put to use in recent initiatives to buttress
legislation like President Obama's Violence Against Women Reauthorization Act
of 2013 (VAWA), which specifically strengthens the government's ability to
protect victims of online harassment, and The Matthew Shepard and James Byrd,
Jr. Hate Crimes Act of 2009. This legislation is likely to be revisited again
in the wake of #Gamergate due to the efforts of legislators like Representative
Katherine Clark and others. With the aid of this research, a more powerful case
could be made and more precise protections could be offered to the victims of
online attacks.
